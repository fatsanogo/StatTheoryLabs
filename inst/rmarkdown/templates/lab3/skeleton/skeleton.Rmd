---
title: "Lab 3: Large Sample Normal Approximation to the Sampling Distribution of the MLE"
output:
  pdf_document:
    keep_tex: true
header-includes:
   - \usepackage{booktabs}
geometry: margin=1.5cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Evaluation

Recall that I'm not going to grade the lab for accuracy, I will just check to see if you have made a good attempt at it. I will post solutions after grading, but it will be helpful to you if you try to work through the lab before checking the solutions.

Places where the line starts with #### 1. (or similar) are places where I'm asking you to do something.

You should definitely feel free to work through this with someone else and just submit one version of the lab. In that case, just put both of your names at the top of the document. Make sure you and your partner submit on lyceum even if it is the same file.

## Simulation and Comparison

Today we will be using the Pareto distribution. The Pareto distribution is a power-law probability distribution, and has only two parameters to describe the distribution: $\alpha$ and $X_m$. $\alpha$ represents the shape parameter of the distribution, and $X_m$ is the scale parameter. Please see [this link](https://dlab.berkeley.edu/news/explaining-80-20-rule-pareto-distribution#:~:text=The%20Pareto%20distribution%20is%20a%20power%2Dlaw%20probability%20distribution%2C%20and,sloped%20(see%20Figure%201).)for more information on Pareto.

Let's obtain an approximation to the sampling distribution of the MLE, as well as an approximation to the sampling distribution of the Method of Moments estimator, by simulation for the pareto distribution. We will do this imagining that we know the true parameters are $x_0 = 1$ and $\alpha = 1.1$. In real life we would not have this information; here, we are just using simulations to explore how the normal approximation works. The idea is to generate many different samples of a fixed size, and calculate the method of moments and maximum likelihood estimates based on each of those samples. Again, in real life we would have access to only a single sample; the idea here is to explore the behavior of these estimators across many samples.

Here is pseudo code for our procedure:

1. Set the sample size `n` to 20 (how large is each sample)
2. Set the number of simulated samples `n_sims` to 10000 (we will generate 10000 different samples of size n an find the MLE and MOM estimates from each)
3. Create a data frame with `n_sims` rows and two variables `alpha_hat_mom` and `alpha_hat_mle`
4. For i in 1, ..., n_sims:
    a. Generate a sample of size n from the Pareto distribution with $x_0 = 1$ and $alpha = 1.1$
    b. Find the method of moments estimate and save it in the results data frame from step 3
    c. Find the maximum likelihod estimate and save it in the results data frame from step 3

In order to do step 4 a, you will need a function to generate samples from a Pareto distribution. Such a function is not built into R, but I have set one up and illustrated its use below:

```{r}
#' Sample from a Pareto distribution
#'
#' @param n sample size
#' @param x_0 location parameter for the Pareto distribution
#' @param alpha scale parameter for the Pareto distribution
#'
#' @return vector of length n, samples from the Pareto distribution.
rpareto <- function(n, x_0, alpha) {
    u <- runif(n, 0, 1)
    x <- x_0 / (1 - u)^{1/alpha}
    return(x)
}
rpareto(n = 20, x_0 = 1, alpha = 1.1)
```

#### 1. Let's implement the procedure outlined above to obtain sampling-based estimates of the sampling distributions of the MOM and MLE estimators.

```{r}
n <- 20
n_sims <- 10000
results <- data.frame(
  alpha_hat_mom = rep(NA, n_sims),
  alpha_hat_mle = rep(NA, n_sims)
)
for(i in seq_len(n_sims)) {
  sample_data <- rpareto(n = n, x_0 = 1, alpha = 1.1)
  results$alpha_hat_mom[i] <- mean(sample_data) / (mean(sample_data) - 1)
  results$alpha_hat_mle[i] <- 1/mean(log(sample_data))
}
```

#### 2. Make a plot with 3 layers on it in different colors: (1) the normal approximation to the sampling distribution of the MLE; (2) the approximation to the sampling distribution of the MLE based on simulation; and (3) the approximation to the sampling distribution of the MOM estimator based on simulation.

```{r, fig.height = 2}
#your code goes here.
```

#### 3. Calculate an estimate of the mean and variance of the MLE and the MOM estimators based on your simulation results.

```{r}
#your code goes here.
```

```{r}
#your code goes here.
```

#### 4. How well does the normal approximation represent the sampling distribution of the MLE?


#### 5. Does the MLE appear to be unbiased?  What about the MoM estimator?

```{r}
#your code goes here.
# Hint you might want to find the difference between the simulation mean and the actual mean which in this case is alpha. This should help you answer this question.
```


#### 6. How does the variance of the sampling distribution of the MLE compare to the variance of the sampling distribution of the MoM estimator?



#### 7. Combine estimates of the bias and variance of the MLE from the simulation-based approximation to the sampling distribution to approximate the Mean Squared Error (MSE) of the MLE.  Do this again to approximate the MSE of the MoM estimator.  Which has a lower mean squared error?

```{r}
#your code goes here.
```

#### 8. Update the sample size to 1000 and re-run your code from part 1.  How do your answers to questions 4, 5, and 6 above change?


```{r}
#your code goes here.
```

```{r, fig.height = 2}
#your code goes here.

```

Bias:

```{r}
#your code goes here.

```

MSE:

```{r}
#your code goes here.

```

## Some logistics for Lab 3

Submit your R Markdown document and knitted file to lyceum as:

LastName-L-03.Rmd 

LastName-L-03.html

To get these files onto your own computer, look in the "Files" pane in the bottom right. Check the boxes next to the two files you want to export, click the "More" button (with a little blue gear), click "Export". Make sure you are exporting the files to a place where you can find them on your own computer. 

This lab was created by Evan L. Ray and was adapted by F. Sanogo.
