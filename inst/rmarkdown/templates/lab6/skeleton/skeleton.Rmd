---
title: 'HW 7: Template'
author: "Your Name"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Calculating MLEs

We can calculate maximum likelihood estimators for particular distributions using R. Here is a skeleton of what a log-likelihood function looks like in R.

```{r, eval = F}
# You will first give your function a name.
    # Then specify the necessary parameters (pars) and data (object) for your function.
    # You will open the function ({)
    # Then you will specify the form of your log-likelihood (logl)
    # You need to tell the function what it should return when you use it
    # Note: the function that we will use to optimize our likelihood only minimizes
    #       functions, therefore we will return the negative log-likelihood
    # Finally, close your function (})
    name = function(pars, object){
          logl = loglikelihood function here
          return(-logl)
}

```

## Poisson Likelihood Function

Let $X_1, X_2, ..., X_n \sim^{iid} Poisson(\lambda)$. Then, the log-likelihood function is given by:

$$l(\lambda) = \sum_{i=1}^n x_i ln(\lambda) - n\lambda - \sum_{i=1}^n ln(x_i!)$$.

Since the last term does not include the parameter $\lambda$, it can be safely ignored for optimization. Thus, the kernel of the log-likelihood function is:

$$l(\lambda) \propto \sum_{i=1}^n x_i ln(\lambda) - n\lambda$$.

We can program this function using the following syntax:

```{r}
poisson.lik <- function(lambda, x) {
  logl <- sum(x) * log(lambda) - length(x) * lambda
  return(-logl)
}

```

Once the log-likelihood function has been declared, then the `nlm` (non-linear minimization) function can be invoked. The minimum specification of this command is `nlm(log-likelihood, starting values, data)`. Here, `starting values` is your (vector of) starting value(s) for the optimization of your parameter.

We will now simulate a data set of 1000 observations from a Poisson($\lambda$ = 3.25) and numerically find the maximum likelihood estimate.


```{r}
# Set the seed so that we all generate the same data set.
set.seed(288)

poiss.data <- rpois(1000, 3.25)

# Note that we are using 1 as the starting value.
out <- nlm(poisson.lik, 1, x = poiss.data)
pois.mle <- out$estimate

pois.mle

```

How did we do? Not too bad considering the true value of $\lambda$ was 3.25. Is this the value that you were expecting? Why or why not?

## Vector Refresher

To create a vector, you use the concatenate function `c()`. To specify the $i$th position of a vector you would use `[i]` on your vector. 

```{r}

pars <- c(1, 2, 3)

pars[2]

```

## Reading in Data Refresher

```{r, eval = F}

gamma_data <- read.csv("gamma_data.csv") ## data frame 
## needs to live in the same folder as this Rmd file

gamma_data$x ## vector

```

## Homework 7, Question 4

Recall that on HW #6, I asked you to write down (but not solve) the equations that you would need to maximize to find the MLEs for $(\alpha, \beta)$ from a Gamma distribution. These partial derivatives are not something that we would want to do by hand (taking the derivative of the gamma function is not too fun), so instead, we will find the MLEs numerically. 

**4a)** Write the code for gamma.lik, the log-likelihood function of a Gamma$(\alpha, \beta)$. Note, that this function will now have a vector for the `pars` argument. 

```{r}

```

**4b)** Read in "gamma_data.csv" from Moodle (make sure it is in the same folder as your Rmd file) and optimize this data with starting values of (1, 1) for $(\alpha, \beta)$.

Note: if you use `read.csv()`, R will read in the data as a data frame and your likelihood function will not be able to handle an object of that class. To avoid this issue, you will have to pull off the `x` column from the data (`dataname$x`) and pass that into your likelihood function.


```{r}


```



**4c)** What are your MLEs for $(\alpha, \beta)$?


```{r}

```
